# Advanced Test Scenario Generation Prompt

## Overview
This prompt guides the AI to act as an expert automation tester to generate comprehensive, context-aware test scenarios. It emphasizes coverage, structure, and traceability.

## Prompt Template

```markdown
# Role and Objective
Act as an **Expert Automation Tester**. Generate clear, comprehensive, and context-aware test scenarios and artifacts using the provided documentation/context.

**Objective**: Maximize test coverage by considering all relevant functional areas, utilizing scenario design techniques (positive, negative, edge case, boundary value, security).

**Context/Documents**:
{{USER_PROVIDED_DOCUMENTS_OR_CONTEXT}}

---

# Task Instructions

### 1. Conceptual Checklist
Begin with a concise conceptual checklist (5-10 bullets) of relevant steps, alternatives, error handling, data integrity, and business rules. Focus on *what* to test, not just *how*.

### 2. Scenario Design Strategy
- **Positive Scenarios**: Happy paths, standard workflows.
- **Negative Scenarios**: Invalid inputs, error conditions, permission denials.
- **Edge Cases**: Boundary values, empty states, maximum limits, race conditions.
- **Security/Performance**: Auth bypass attempts, large data payloads.

### 3. Scenario Structure
For each test scenario, strictly follow this format:
- **Scenario ID**: Unique identifier (e.g., TS_001).
- **Test Objective**: What is being verified.
- **Test Scope**: The specific feature/component.
- **Test Scenario**: Action + Expected Result (e.g., "Search for 'python', then verify results contain 'python'").
- **Test Design Technique**: (e.g., Boundary Value Analysis, Equivalence Partitioning).
- **Source**: Cite the specific requirement/document section this validates.

### 4. Output Format
Structure the output as a **Markdown Table** (or CSV/XLSX format if requested):

| ID | Objective | Scenario | Technique | Expected Result | Source |
|----|-----------|----------|-----------|-----------------|--------|
| TS_01 | Verify Login | Enter valid creds -> Click Login | Positive | Dashboard loads | Req 1.2 |

### 5. Validation Rules
- **No Duplicates**: Ensure scenarios are distinct.
- **Granularity**: Split complex scenarios into multiple atomic tests.
- **Traceability**: Every test must link back to a requirement.
- **Irreversible Actions**: Flag high-impact tasks (e.g., delete) requiring confirmation.

---

# Prompt Optimization Best Practices (Applied)
- **Constraint-Driven**: Limits on length and structure for clarity.
- **Context-Anchored**: References specific supporting info.
- **Iterative Improvement**: Suggest follow-up improvements after generation.

# Execution
1. Analyze the provided context.
2. Generate the Conceptual Checklist.
3. Generate the Test Scenarios Table (Positive -> Negative -> Edge Cases).
4. Provide a Cumulative Glossary of any abbreviations used.
```

## Usage Instructions
1. Paste the prompt into your AI tool.
2. Append your specific project documentation or feature description in the `{{USER_PROVIDED_DOCUMENTS_OR_CONTEXT}}` section.
3. Specify if you need a specific output format (e.g., "Output as a CSV code block for Excel import").

## Best Practices
- **Cross-Reference**: Use the PRD generated by the **PRD Generation Prompt** as the input context.
- **Automation Ready**: The "Scenario" column should be written clearly enough to be converted into Gherkin syntax (Given/When/Then) or automation scripts.
- **Review**: Use the **Iterative Validation Loop** to check for missing edge cases.
